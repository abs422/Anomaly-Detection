{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1qnBsFLdUPOyBsNQD2VOGhaf-sTsn87HJ",
      "authorship_tag": "ABX9TyOpOm8Z3yjlTmBbzmeHPzko",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abs422/Anomaly-Detection/blob/Graph-Adversarial-Networks/wgan_gp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/f-AnoGAN/tflib')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/f-AnoGAN/')\n"
      ],
      "metadata": {
        "id": "JOtzdIDdZ_hf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zuqljFyTZmeR"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Training of the WGAN-GP model\n",
        "\n",
        "Copyright (c) 2017 Ishaan Gulrajani\n",
        "Copyright (c) 2018 Thomas Schlegl ... modified and extended\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import os, sys\n",
        "import numpy as np\n",
        "import re\n",
        "sys.path.append(os.getcwd())\n",
        "\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import functools\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tflib as lib\n",
        "import tflib.ops.linear\n",
        "import tflib.ops.conv2d\n",
        "import tflib.ops.batchnorm\n",
        "import tflib.ops.deconv2d\n",
        "import tflib.save_images\n",
        "import tflib.img_loader\n",
        "import tflib.ops.layernorm\n",
        "import tflib.plot\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class bcolors:\n",
        "    PINK = '\\033[95m'\n",
        "    BLUE = '\\033[94m'\n",
        "    GREEN = '\\033[92m'\n",
        "    YELLOW = '\\033[93m'\n",
        "    RED = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "\n",
        "timestamp = time.strftime(\"%Y-%m-%d-%H%M\")\n",
        "filename = os.path.splitext(os.path.basename(sys.argv[0]))[0]\n",
        "# filename = os.path.basename(__file__).strip('.ipynb')\n",
        "\n",
        "\n",
        "MODE = 'wgan-gp'\n",
        "RAND_SAMPLING = 'normal' # 'unif'\n",
        "DIM = 64 # Model dimensionality\n",
        "CRITIC_ITERS = 5\n",
        "N_GPUS = 1\n",
        "BATCH_SIZE = 64\n",
        "LAMBDA = 10 # Gradient penalty hyperpar\n",
        "OUTPUT_DIM = 64*64*1 # Number of pixels in each image\n",
        "ZDIM = 128\n",
        "TRAIN_EPOCHS = 7\n",
        "ZSPACE_SMPL_NRIMG = 5\n",
        "ZSPACE_SMPL_PTS = 13\n",
        "checkpoint_iter = None\n",
        "\n",
        "\n",
        "run_name = \"%s_%s_crIt%d_%s\" %(filename, RAND_SAMPLING, CRITIC_ITERS, timestamp)\n",
        "checkpoint_dir = os.path.join(\"wganTrain\", run_name, \"checkpoints\")\n",
        "log_dir    = os.path.join(\"wganTrain\", run_name, \"logs\")\n",
        "samples_dir  = os.path.join(\"wganTrain\", run_name, \"samples\")\n",
        "z_interp_dir = os.path.join(\"wganTrain\", run_name, \"z_interp\")\n",
        "\n",
        "\n",
        "print(bcolors.GREEN + \"\\n=== WGAN-GP TRAINING PARAMETERS ===\" + bcolors.ENDC)\n",
        "lib.print_model_settings(locals().copy())\n",
        "\n",
        "DEVICES = ['/gpu:{}'.format(i) for i in range(N_GPUS)]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPwQN6rW23mt",
        "outputId": "73a7bcfb-f0cb-4d22-ab85-5444d4aefd81"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m\n",
            "=== WGAN-GP TRAINING PARAMETERS ===\u001b[0m\n",
            "Uppercase local vars:\n",
            "\tBATCH_SIZE: 64\n",
            "\tCRITIC_ITERS: 5\n",
            "\tDIM: 64\n",
            "\tLAMBDA: 10\n",
            "\tMODE: wgan-gp\n",
            "\tN_GPUS: 1\n",
            "\tOUTPUT_DIM: 4096\n",
            "\tRAND_SAMPLING: normal\n",
            "\tTRAIN_EPOCHS: 7\n",
            "\tZDIM: 128\n",
            "\tZSPACE_SMPL_NRIMG: 5\n",
            "\tZSPACE_SMPL_PTS: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Now you can use the Session class\n",
        "sess = tf.Session()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsOfMLS38oNs",
        "outputId": "e9871c84-3afe-47db-e699-235310d336f5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def Normalize(name, axes, inputs):\n",
        "    if ('Discriminator' in name) and (MODE == 'wgan-gp'):\n",
        "        if axes != [0,2,3]:\n",
        "            raise Exception('Layernorm over non-standard axes is unsupported')\n",
        "        return lib.ops.layernorm.Layernorm(name,[1,2,3],inputs)\n",
        "    else:\n",
        "        return lib.ops.batchnorm.Batchnorm(name,axes,inputs,fused=True)\n",
        "\n",
        "def my_Normalize(name, inputs, is_training):\n",
        "    if ('Discriminator' in name) and (MODE == 'wgan-gp'):\n",
        "        return lib.ops.layernorm.Layernorm(name,[1,2,3],inputs)\n",
        "    else:\n",
        "        return tf.layers.batch_normalization(inputs, axis=1, training=is_training, name=name)\n",
        "\n",
        "def ConvMeanPool(name, input_dim, output_dim, filter_size, inputs, he_init=True, biases=True):\n",
        "    output = lib.ops.conv2d.Conv2D(name, input_dim, output_dim, filter_size, inputs, he_init=he_init, biases=biases)\n",
        "    output = tf.add_n([output[:,:,::2,::2], output[:,:,1::2,::2], output[:,:,::2,1::2], output[:,:,1::2,1::2]]) / 4.\n",
        "    return output\n",
        "\n",
        "def MeanPoolConv(name, input_dim, output_dim, filter_size, inputs, he_init=True, biases=True):\n",
        "    output = inputs\n",
        "    output = tf.add_n([output[:,:,::2,::2], output[:,:,1::2,::2], output[:,:,::2,1::2], output[:,:,1::2,1::2]]) / 4.\n",
        "    output = lib.ops.conv2d.Conv2D(name, input_dim, output_dim, filter_size, output, he_init=he_init, biases=biases)\n",
        "    return output\n",
        "\n",
        "def UpsampleConv(name, input_dim, output_dim, filter_size, inputs, he_init=True, biases=True):\n",
        "    output = inputs\n",
        "    output = tf.concat([output, output, output, output], 1)\n",
        "    output = tf.transpose(output, [0,2,3,1])\n",
        "    output = tf.depth_to_space(output, 2)\n",
        "    output = tf.transpose(output, [0,3,1,2])\n",
        "    output = lib.ops.conv2d.Conv2D(name, input_dim, output_dim, filter_size, output, he_init=he_init, biases=biases)\n",
        "    return output\n",
        "\n",
        "def ResidualBlock(name, input_dim, output_dim, filter_size, inputs, is_training=True, resample=None, he_init=True):\n",
        "    \"\"\"\n",
        "    resample: None, 'down', or 'up'\n",
        "    \"\"\"\n",
        "    if resample=='down':\n",
        "        conv_shortcut = MeanPoolConv\n",
        "        conv_1        = functools.partial(lib.ops.conv2d.Conv2D, input_dim=input_dim, output_dim=input_dim)\n",
        "        conv_2        = functools.partial(ConvMeanPool, input_dim=input_dim, output_dim=output_dim)\n",
        "    elif resample=='up':\n",
        "        conv_shortcut = UpsampleConv\n",
        "        conv_1        = functools.partial(UpsampleConv, input_dim=input_dim, output_dim=output_dim)\n",
        "        conv_2        = functools.partial(lib.ops.conv2d.Conv2D, input_dim=output_dim, output_dim=output_dim)\n",
        "    elif resample==None:\n",
        "        conv_shortcut = lib.ops.conv2d.Conv2D\n",
        "        conv_1        = functools.partial(lib.ops.conv2d.Conv2D, input_dim=input_dim,  output_dim=input_dim)\n",
        "        conv_2        = functools.partial(lib.ops.conv2d.Conv2D, input_dim=input_dim, output_dim=output_dim)\n",
        "    else:\n",
        "        raise Exception('invalid resample value')\n",
        "\n",
        "    if output_dim==input_dim and resample==None:\n",
        "        shortcut = inputs # Identity skip-connection\n",
        "    else:\n",
        "        shortcut = conv_shortcut(name+'.Shortcut', input_dim=input_dim, output_dim=output_dim, filter_size=1,\n",
        "                                 he_init=False, biases=True, inputs=inputs)\n",
        "\n",
        "    output = inputs\n",
        "    if is_training is not None:\n",
        "        output = my_Normalize(name+'.BN1', output, is_training)\n",
        "    else:\n",
        "        output = Normalize(name+'.BN1', [0,2,3], output)\n",
        "    output = tf.nn.relu(output)\n",
        "    output = conv_1(name+'.Conv1', filter_size=filter_size, inputs=output, he_init=he_init, biases=False)\n",
        "    if is_training is not None:\n",
        "        output = my_Normalize(name+'.BN2', output, is_training)\n",
        "    else:\n",
        "        output = Normalize(name+'.BN2', [0,2,3], output)\n",
        "    output = tf.nn.relu(output)\n",
        "    output = conv_2(name+'.Conv2', filter_size=filter_size, inputs=output, he_init=he_init)\n",
        "\n",
        "    return shortcut + output\n",
        "\n",
        "\n",
        "def GoodGenerator(n_samples, noise=None, rand_sampling=RAND_SAMPLING, dim=DIM, nonlinearity=tf.nn.relu, z_out=False, is_training=True, reuse=None):\n",
        "    with tf.variable_scope('Generator', reuse=reuse):\n",
        "        if noise is None:\n",
        "            if rand_sampling == 'unif':\n",
        "                noise = tf.random_uniform([n_samples, ZDIM], minval=-1., maxval=1.)\n",
        "            elif rand_sampling == 'normal':\n",
        "                noise = tf.random_normal([n_samples, ZDIM])\n",
        "\n",
        "        output = lib.ops.linear.Linear('Generator.Input', ZDIM, 4*4*8*dim, noise)\n",
        "        output = tf.reshape(output, [-1, 8*dim, 4, 4])\n",
        "\n",
        "        output = ResidualBlock('Generator.Res1', 8*dim, 8*dim, 3, output, is_training=is_training, resample='up')\n",
        "        output = ResidualBlock('Generator.Res2', 8*dim, 4*dim, 3, output, is_training=is_training, resample='up')\n",
        "        output = ResidualBlock('Generator.Res3', 4*dim, 2*dim, 3, output, is_training=is_training, resample='up')\n",
        "        output = ResidualBlock('Generator.Res4', 2*dim, 1*dim, 3, output, is_training=is_training, resample='up')\n",
        "\n",
        "        if is_training is not None:\n",
        "            output = my_Normalize('Generator.OutputN', output, is_training)\n",
        "        else:\n",
        "            output = Normalize('Generator.OutputN', [0,2,3], output)\n",
        "        output = tf.nn.relu(output)\n",
        "        output = lib.ops.conv2d.Conv2D('Generator.Output', 1*dim, 1, 3, output)\n",
        "        output = tf.tanh(output)\n",
        "\n",
        "    if z_out:\n",
        "        return tf.reshape(output, [-1, OUTPUT_DIM]), noise\n",
        "    else:\n",
        "        return tf.reshape(output, [-1, OUTPUT_DIM])\n",
        "\n",
        "\n",
        "def GoodDiscriminator(inputs, dim=DIM, is_training=False, reuse=None, out_feats=True):\n",
        "    with tf.variable_scope('Discriminator', reuse=reuse):\n",
        "        output = tf.reshape(inputs, [-1, 1, 64, 64])\n",
        "        output = lib.ops.conv2d.Conv2D('Discriminator.Input', 1, dim, 3, output, he_init=False)\n",
        "\n",
        "        output = ResidualBlock('Discriminator.Res1', dim, 2*dim, 3, output, is_training=is_training, resample='down')\n",
        "        output = ResidualBlock('Discriminator.Res2', 2*dim, 4*dim, 3, output, is_training=is_training, resample='down')\n",
        "        output = ResidualBlock('Discriminator.Res3', 4*dim, 8*dim, 3, output, is_training=is_training, resample='down')\n",
        "        output = ResidualBlock('Discriminator.Res4', 8*dim, 8*dim, 3, output, is_training=is_training, resample='down')\n",
        "\n",
        "        output = tf.reshape(output, [-1, 4*4*8*dim])\n",
        "        out_features = output\n",
        "        output = lib.ops.linear.Linear('Discriminator.Output', 4*4*8*dim, 1, output)\n",
        "\n",
        "    if out_feats:\n",
        "        return tf.reshape(output, [-1]), out_features\n",
        "    else:\n",
        "        return tf.reshape(output, [-1])\n",
        "\n",
        "\n",
        "def save(session, saver, checkpoint_dir, step):\n",
        "    print(\" [*] Saving checkpoint (step %d) ...\" %step)\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "    saver.save( session,\n",
        "                os.path.join(checkpoint_dir, \"%s.model\" %MODE),\n",
        "                global_step=step)\n",
        "\n",
        "\n",
        "def load(session, saver, checkpoint_dir, checkpoint_iter=None):\n",
        "    print(\" [*] Reading checkpoints...\")\n",
        "\n",
        "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
        "    if ckpt and ckpt.model_checkpoint_path:\n",
        "        if checkpoint_iter is not None:\n",
        "            last_ckpt_epoch = re.match(r'.*.model-(\\d+)', ckpt.model_checkpoint_path).group(1)\n",
        "            target_ckpt_path = re.sub( last_ckpt_epoch, str(checkpoint_iter), ckpt.model_checkpoint_path)\n",
        "            saver.restore(session, target_ckpt_path)\n",
        "            idxx = target_ckpt_path.rfind('/')\n",
        "            ckpt_name = target_ckpt_path[idxx+1:]\n",
        "        else:\n",
        "            saver.restore(session, ckpt.model_checkpoint_path)\n",
        "            idxx = ckpt.model_checkpoint_path.rfind('/')\n",
        "            ckpt_name = ckpt.model_checkpoint_path[idxx+1:]\n",
        "        return True, ckpt_name\n",
        "    else:\n",
        "        return False, ''\n",
        "\n"
      ],
      "metadata": {
        "id": "LQSfPFrl5kvn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train():\n",
        "    Generator, Discriminator = GoodGenerator, GoodDiscriminator\n",
        "\n",
        "    for dir_path in [checkpoint_dir, log_dir, samples_dir, z_interp_dir]:\n",
        "        if not os.path.isdir(dir_path):\n",
        "            os.makedirs(dir_path)\n",
        "\n",
        "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as session:\n",
        "        all_real_data_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE, 1, 64, 64])\n",
        "        if tf.__version__.startswith('1.'):\n",
        "            split_real_data_conv = tf.split(all_real_data_conv, len(DEVICES))\n",
        "            print(\"\\n\\nDEVICES: %s\\n\\n\" %DEVICES)\n",
        "        else:\n",
        "            split_real_data_conv = tf.split(0, len(DEVICES), all_real_data_conv)\n",
        "        gen_costs, disc_costs = [],[]\n",
        "\n",
        "        for device_index, (device, real_data_conv) in enumerate(zip(DEVICES, split_real_data_conv)):\n",
        "            with tf.device(device):\n",
        "                real_data = tf.reshape(2*((tf.cast(real_data_conv, tf.float32)/255.)-.5), [BATCH_SIZE/len(DEVICES), OUTPUT_DIM])\n",
        "                fake_data = Generator(BATCH_SIZE/len(DEVICES), rand_sampling=RAND_SAMPLING, is_training=True)\n",
        "\n",
        "                disc_real = Discriminator(real_data, out_feats=False)\n",
        "                disc_fake = Discriminator(fake_data, reuse=True, out_feats=False)\n",
        "\n",
        "                if MODE == 'wgan-gp':\n",
        "                    gen_cost = -tf.reduce_mean(disc_fake)\n",
        "                    disc_cost = tf.reduce_mean(disc_fake) - tf.reduce_mean(disc_real)\n",
        "\n",
        "                    alpha = tf.random_uniform(\n",
        "                        shape=[BATCH_SIZE/len(DEVICES),1].astype(np.int32), \n",
        "                        minval=0.,\n",
        "                        maxval=1.\n",
        "                    )\n",
        "                    differences = fake_data - real_data\n",
        "                    interpolates = real_data + (alpha*differences)\n",
        "                    gradients = tf.gradients(Discriminator(interpolates, reuse=True, out_feats=False), [interpolates])[0]\n",
        "                    slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
        "                    gradient_penalty = tf.reduce_mean((slopes-1.)**2)\n",
        "                    disc_cost += LAMBDA*gradient_penalty\n",
        "\n",
        "                gen_costs.append(gen_cost)\n",
        "                disc_costs.append(disc_cost)\n",
        "\n",
        "        gen_cost = tf.add_n(gen_costs) / len(DEVICES)\n",
        "        disc_cost = tf.add_n(disc_costs) / len(DEVICES)\n",
        "\n",
        "        if MODE == 'wgan-gp':\n",
        "            t_vars = tf.trainable_variables()\n",
        "            gen_vars = [var for var in t_vars if 'Generator' in var.name]\n",
        "            dis_vars = [var for var in t_vars if 'Discriminator' in var.name]\n",
        "\n",
        "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "            update_ops_gen = [var for var in update_ops if 'Generator' in var.name] \n",
        "            update_ops_dis = [var for var in update_ops if 'Discriminator' in var.name] \n",
        "\n",
        "            with tf.control_dependencies(update_ops_gen):\n",
        "                gen_train_op = tf.train.AdamOptimizer(learning_rate=1e-4, beta1=0., beta2=0.9).minimize(gen_cost,\n",
        "                                              var_list=gen_vars, colocate_gradients_with_ops=True)\n",
        "            with tf.control_dependencies(update_ops_dis):\n",
        "                disc_train_op = tf.train.AdamOptimizer(learning_rate=1e-4, beta1=0., beta2=0.9).minimize(disc_cost,\n",
        "                                               var_list=dis_vars, colocate_gradients_with_ops=True)\n",
        "\n",
        "\n",
        "        # For generating samples\n",
        "        if RAND_SAMPLING == 'unif':\n",
        "            fixed_noise = tf.constant(np.random.uniform(-1, 1, size=(BATCH_SIZE, ZDIM)).astype('float32'))\n",
        "        elif RAND_SAMPLING == 'normal':\n",
        "            fixed_noise = tf.constant(np.random.normal(size=(BATCH_SIZE, ZDIM)).astype('float32'))\n",
        "\n",
        "        all_fixed_noise_samples = []\n",
        "        for device_index, device in enumerate(DEVICES):\n",
        "            n_samples = BATCH_SIZE / len(DEVICES)\n",
        "            all_fixed_noise_samples.append(Generator(n_samples, noise=fixed_noise[device_index*n_samples:(device_index+1)*n_samples], rand_sampling=RAND_SAMPLING, is_training=False, reuse=True ) )\n",
        "        if tf.__version__.startswith('1.'):\n",
        "            all_fixed_noise_samples = tf.concat(all_fixed_noise_samples, 0)\n",
        "        else:\n",
        "            all_fixed_noise_samples = tf.concat(0, all_fixed_noise_samples)\n",
        "\n",
        "        def generate_image(epoch, iteration):\n",
        "            samples = session.run(all_fixed_noise_samples)\n",
        "            samples = ((samples+1.)*(255.99/2)).astype('int32')\n",
        "            lib.save_images.save_images(samples.reshape((BATCH_SIZE, 1, 64, 64)), '{}/samples_epoch{}-{}.png'.format(samples_dir, epoch, iteration))\n",
        "\n",
        "\n",
        "        # Dataset iterator\n",
        "        train_gen,_ = lib.img_loader.load(BATCH_SIZE, 'wgan_train')\n",
        "\n",
        "        nr_training_samples = lib.img_loader.get_nr_training_samples(BATCH_SIZE)\n",
        "        nr_iters_per_epoch = nr_training_samples//BATCH_SIZE\n",
        "\n",
        "        def inf_train_gen():\n",
        "            while True:\n",
        "                for (images,) in train_gen():\n",
        "                    yield images\n",
        "\n",
        "        # Save a batch of ground-truth samples\n",
        "        _x = inf_train_gen().next()\n",
        "        _x_r = session.run(real_data, feed_dict={real_data_conv: _x[:BATCH_SIZE/N_GPUS]})\n",
        "        _x_r = ((_x_r+1.)*(255.99/2)).astype('int32')\n",
        "        lib.save_images.save_images(_x_r.reshape((BATCH_SIZE/N_GPUS, 1, 64, 64)), '{}/samples_groundtruth.png'.format(samples_dir))\n",
        "\n",
        "\n",
        "        # EVALUATION: z-interpolation ******\n",
        "        eval_query_noise = tf.placeholder(tf.float32, shape=[ZSPACE_SMPL_PTS, ZDIM].astype(np.int32))\n",
        "        zeval_gen_imgs = Generator(ZSPACE_SMPL_PTS, noise=eval_query_noise, rand_sampling=RAND_SAMPLING, is_training=False, reuse=True )\n",
        "\n",
        "        def get_z_interpolations(smpl_pts, z_dim=ZDIM, v_len_lim=0.5):\n",
        "            z_samples = np.zeros((smpl_pts, z_dim), dtype=np.float32)\n",
        "\n",
        "            v_max = np.ones((1,100))*2  # *2 ... => 2 = [-1..1] \n",
        "            v_len_max = np.sqrt( (v_max**2).sum() ) # vector_length of v_max\n",
        "            v_len_limes = v_len_max * v_len_lim\n",
        "            v_len = 0\n",
        "\n",
        "            while v_len<v_len_limes:\n",
        "                if RAND_SAMPLING == 'unif':\n",
        "                    z_p1 = np.random.uniform(-1, 1, [1, z_dim]).astype(np.float32)\n",
        "                    z_p2 = np.random.uniform(-1, 1, [1, z_dim]).astype(np.float32)\n",
        "                elif RAND_SAMPLING == 'normal':\n",
        "                    z_p1 = np.random.normal(size=(1, ZDIM)).astype('float32')\n",
        "                    z_p2 = np.random.normal(size=(1, ZDIM)).astype('float32')\n",
        "\n",
        "                v = z_p2 - z_p1\n",
        "                v_len = np.sqrt( (v**2).sum() ) # vector_length of v\n",
        "\n",
        "            steps = np.linspace(0., 1., smpl_pts)\n",
        "            for i,s in enumerate(steps):\n",
        "                z_samples[i, :] = z_p1 + s*v\n",
        "\n",
        "            z_imgs = session.run(zeval_gen_imgs, feed_dict={eval_query_noise: z_samples})\n",
        "            return ((z_imgs+1.)*(255.99/2)).astype('int32')\n",
        "\n",
        "\n",
        "        saver = tf.train.Saver(max_to_keep=10)\n",
        "        session.run(tf.global_variables_initializer())\n",
        "        isLoaded, ckpt = load(session, saver, checkpoint_dir, checkpoint_iter)\n",
        "        start_iter = 0\n",
        "\n",
        "        # Train loop\n",
        "        iteration = 0\n",
        "        for epoch in tqdm(range(TRAIN_EPOCHS)):\n",
        "            gen = inf_train_gen()\n",
        "            while iteration < ((epoch+1)*(nr_iters_per_epoch-CRITIC_ITERS)):\n",
        "                start_time = time.time()\n",
        "\n",
        "                ## -- TRAIN generator --\n",
        "                if (iteration+1) > 1:\n",
        "                    _gen_cost, _ = session.run([gen_cost, gen_train_op])\n",
        "\n",
        "                ## -- TRAIN critic --\n",
        "                disc_iters = CRITIC_ITERS\n",
        "                for i in range(disc_iters):\n",
        "                    _data = gen.next()\n",
        "                    iteration += 1\n",
        "                    _disc_cost, _ = session.run([disc_cost, disc_train_op], feed_dict={all_real_data_conv: _data})\n",
        "\n",
        "                ## -- LOGGING **\n",
        "                lib.plot.tickit(iteration)\n",
        "\n",
        "                if (iteration == (3*disc_iters)) or (iteration % (100*disc_iters) == 0):\n",
        "                    lib.plot.plot('train disc cost', _disc_cost)\n",
        "                    lib.plot.plot('train gen cost', _gen_cost)\n",
        "                    lib.plot.plot('time', time.time() - start_time)\n",
        "\n",
        "                if (iteration == (10*disc_iters)) or (iteration == (100*disc_iters)) or ( iteration % (1000*disc_iters) == 0):\n",
        "                    generate_image(epoch+1, iteration)\n",
        "\n",
        "\n",
        "                if (iteration < 10) or ( iteration % (100*disc_iters) == 0):\n",
        "                    lib.plot.flush(log_dir)\n",
        "\n",
        "                    total_samples_seen = iteration * BATCH_SIZE\n",
        "                    if (epoch+1)==1:\n",
        "                        nr_samples_within_epoch = total_samples_seen\n",
        "                    else:\n",
        "                        nr_samples_within_epoch = np.mod(total_samples_seen, epoch*(nr_iters_per_epoch-CRITIC_ITERS))\n",
        "                    \n",
        "                    print(bcolors.GREEN + \"\\tSaw real samples of %d full epochs and %10d additinal samples .. \" \\\n",
        "                                            %(epoch, nr_samples_within_epoch) + \\\n",
        "                                            \"(%.3f%% of epoch done!)\" \\\n",
        "                                            %(float(nr_samples_within_epoch)/nr_training_samples) + bcolors.ENDC)\n",
        "\n",
        "                if (iteration == (100*disc_iters)) or (iteration==(start_iter+(1000*disc_iters))) or (iteration % (1000*disc_iters) == 0):\n",
        "                    z_imgs_out = np.zeros((ZSPACE_SMPL_PTS,64*ZSPACE_SMPL_NRIMG,64), dtype=np.int32)\n",
        "                    for _zi in range(ZSPACE_SMPL_NRIMG):\n",
        "                        z_space_smpls = get_z_interpolations( ZSPACE_SMPL_PTS )\n",
        "                        z_imgs_out[:,_zi*64:(_zi+1)*64,:] = z_space_smpls.reshape(ZSPACE_SMPL_PTS,64,64)\n",
        "                    lib.save_images.save_images_as_row( z_imgs_out, os.path.join(z_interp_dir, 'z_smpls-epoch%d-%05d.png'%(epoch+1, iteration)) )\n",
        "\n",
        "            print(bcolors.BLUE + \"\\nEND OF EPOCH - SAVING CHECKPOINT\\n\" + bcolors.ENDC)\n",
        "            save(session, saver, checkpoint_dir, epoch+1)\n",
        "            generate_image(epoch+1, iteration)\n",
        "\n",
        "        # SAVE FINAL MODEL\n",
        "        save(session, saver, checkpoint_dir, epoch+1)\n",
        "        print(bcolors.BLUE + \"\\nSAVING CHECKPOINT\" + bcolors.ENDC)\n",
        "        print(bcolors.BLUE + \"Training done!\\n\" + bcolors.ENDC)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6uNuoAie817R"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "560tx3YJOMGQ",
        "outputId": "8b69cfef-4121-4626-e557-6405dc60f01a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-5021961d5ada>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-6607ec651ef1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdevice_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_data_conv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_real_data_conv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mreal_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_data_conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_DIM\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0mfake_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_sampling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRAND_SAMPLING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_SatisfiesTypeConstraint\u001b[0;34m(dtype, attr_def, param_name)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mallowed_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m       raise TypeError(\n\u001b[0m\u001b[1;32m     57\u001b[0m           \u001b[0;34mf\"Value passed to parameter '{param_name}' has DataType \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m           \u001b[0;34mf\"{dtypes.as_dtype(dtype).name} not in list of allowed values: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Value passed to parameter 'shape' has DataType float32 not in list of allowed values: int32, int64"
          ]
        }
      ]
    }
  ]
}